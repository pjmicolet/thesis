\chapter{Introduction}
%From StreamIt paper
Multicore processors are now common in all computing systems ranging from mobile devices to data centers.
As advances in single threaded performance have slowed, multicore processors have offered a way to use the increasing numbers of transistors available.
However, designing processors that scale to a large number of cores is difficult and a shift towards tiled architecture seems inevitable.
A tiled architecture such as Tilera~\cite{bell2008tile} or Raw~\cite{waingold1997raw} is composed of smaller simpler cores that are placed on a regular grid.
This improves hardware scalability and enables multi-threaded applications to exploit the large core count.

% Tiled architecture problem: cores too weak => need reconfiguration
However, workloads that require high single threaded performance are penalized by the simple nature of each core~\cite{eyerman2010amdahl}.
One solution to this problem is heterogeneous multicores which utilize cores with different levels of power and performance.
Although heterogeneous multicores are common place in mobile devices, they have little reconfiguration or adaptive capabilities (\eg only two type of cores available for ARM big.LITTLE).
Dynamic multicore processors offer a solution to this problem by allowing cores to compose (or fuse) together~\cite{ipek2007CoreFusion} into larger logical cores to accelerate single threads.
This produces ``on-demand'' heterogeneity where cores are grouped to adapt to the workload's demand.

\section{The Problem}

\paragraph*{Dynamic multicore processor reconfiguration}
Whilst there exists a multitude of proposed dynamic multicore processor architectures ~\cite{MittalSurv2016} work on understanding when to compose cores, or what type of programs can benefit the most out of core composition is scarce.
A 16 core DMP for example has over 15,000 configurations when executing multi-threaded programs, making exhaustive search of the space impractical.
Therefore, without some method of automating the reconfiguration of the processor the programmer must have intimate knowledge of both the architecture and the programs that will execute on them.

Previous work on determining how many cores must be composed for a given program at runtime or ahead of time focus on using profiling information~\cite{pricopiSchedCoreComp2014} or heuristics based on observations~\cite{gulati2008multitaskingdmc}.
They consider core composition to be a \textit{black box}: instead of trying to understand what features of a program lead to good performance, they will instead evaluate it on different core composition sizes and determine the best one.
This approach makes DMPs less practical as it increases the amount of work required to ensure that workloads benefit from core composition.

If the system could determine the correct configuration of the processor by analysing the source-code or assembly of a program, then this would make the process of getting the best performance lightweight.
This would allow programers to modify their programs without having to extensively re-profile their applications, making dynamic multicore processors more approachable.

\paragraph*{Benefiting from core composition}
Not all applications will benefit from executing on a core composition, which can reduce the attractiveness of implementing the feature in a processor.
The lack of performance may be due to the fact that the programs were not initially designed to be executed on a system that supports core composition.
Programmers may have to re-design their code to ensure that a program that currently does not perform any better could not be re-written to benefit from the new hardware.

However, there exists no information as to what optimisations may help improve the performance of applications on a dynamic multicore processor.
Furthermore, a programmer may not necessarily have access to a compiler that provides passes that are targetted towards such systems.
In this case, it is important to explore source-level optimisations and study how they can help increase the performance of programs on core composition.
By underlining which optimisations will lead to performance improvements, this encourages the ease-of-use of dynamic multicore processors.

\paragraph*{Core composition mechanisms} 
Finally, as the concept of dynamic multicore processors is still relatively new compared to other processor designs, the currently proposed techniques may not be enough to maximise performance.
For example, core composition exploits instruction level parallelism by executing a single thread through the use of aggressive speculation.
Yet, there the architectures proposed in research do not discuss how data-dependencies, that often occur when many instructions are executing in parallel, can be resolved quickly.
This means that dynamic multicore processors will not improve performance to the fullest of their capacities.

It is therefore important to critically analyse where the current bottlenecks of core composition are from a hardware perspective.
By proposing solutions to these bottlenecks, core composition can become more effective at improving the performance of programs.
Modifications to the hardware can even help dynamic multicore processors become more adaptable to new types of programs, once again making them more practical.


\section{Contributions}
This thesis tackles the three problems that were previously described through the use of different techniques.

In order to provide a more general solution towards automating the reconfiguration of a DMP, both at runtime and ahead of time, a set of machine learning models that are able to automatically make configuration decisions based on features of the software are proposed.
This thesis presents a design methodology for generating these models that use either program features that can be extracted at the source level or features that can be used at runtime, to determine when and how to configure the cores.
These models are not influenced by hand-picked heuresitics, but instead are generated by exploring how different configurations affect performance, and analysing how different programs' performance is improved by core composition.
By using machine learning, the processor can automatically be reconfigured ahead of time to improve the performance of multithreaded applications, or at runtime to reduce energy consumption.

This thesis also provides an analysis of how different features of the source-code affect the speedup that can be gained from core composition.
This is achieved by exploring a set of source-level optimisations and studying the generated code of applications that perform both well and poorly.
The analysis provides insights on when core composition should be used, and how programs may be modified to get more performance.

Finally, the current shortcomings of core composition are brought forward.
The two main features of the hardware that are analysed are how instructions are fetched when cores are composed and how data-dependencies affect the performance of large core compositions.
By providing a new fetching scheme, and implementing a value predictor which can speculate the results of instructions, this thesis shows that the mechanisms of core composition can be improved.


\section{Structure}
The overall aim of this thesis is to provide methods of making DMPs more practical, from automated reconfiguration to new hardware that improves the overall performance of the DMP.
The structure of the thesis is as follows:

\textbf{Chapter ~\ref{chp:Background}} provides information on the different topics approached throughout this thesis. The topics involve the reconfiguration mechanisms of DMPs, the EDGE architecture, how value prediction works and the different machine learning techniques used throughout this thesis.

\textbf{Chapter ~\ref{chp:rw}} presents the related work. This covers previously proposed DMP processors and the different offline and online reconfiguration schemes that are suggested. 
This is followed by a discussion of work done on compiler optimisations for EDGE, the different hardware techniques that improve energy efficiency, other proposed value predictors and different types of speculative hardware.

\textbf{Chapter ~\ref{chp:setup}} covers the setup of the cycle-accurate simulator used throughout this thesis.

\textbf{Chapter ~\ref{chp:streamit}} explores how a dynamic multicore processor can be configured to improve the performance of multi-threaded streaming applications.
The chapter demonstrates that a mix of core composition and multithreading is requried to get the best speedup for these applications.
A machine learning model is then trained to determine a good configuration of the processor based on source-code information derived from the application.
This chapter is based on the work previously published in ~\cite{micolet2016dmpstream}.

\textbf{Chapter ~\ref{chp:cases}} uses dynamic reconfiguration to reduce energy consumption whilst maintaining the same performance as the optimal static ahead of time configuration.
The chapter first covers some of the factors that affect the performance of core compositions, such as branch prediction accuracy requirements folowed by a study of how dynamically adapting the processor at runtime can reduce energy consumption.
A machine learning model that can determine the correct size of a core composition at runtime, based on the types of instruction being executed is then designed.
The chapter is based on the work previously published in ~\cite{micolet2017cases}.

\textbf{Chapter ~\ref{chp:hardchanges}} presents modifications to the hardware that allow larger core compositions to perform better in the average situation.
The modifications involve a new fetching mechanism that ensures each core can fetch blocks independently and in a round robin fashion and the use of value prediction to minimise stress on the network on chip and reduce the effect of data dependencies between cores.

\textbf{Chapter ~\ref{chp:conclusion}} finally concludes this thesis by summarising the contributions, providing critical analysis and presenting future work in the field of dynamic multicore processors.