% Software point of view: the problem
While dynamic multicore processors sound like a promising approach, they come with their own challenges, particularly on the software side~\cite{wells2009needfordmc}.
In most parallel programming models such as OpenMP, the user is directly responsible for mapping parallelism to the hardware; a difficult and time consuming task.
This problem is further exacerbated when hardware resources can be combined since programmers have to take into account the dynamic behavior of the architecture~\cite{bower2008impactd}.

% Solution for the software: data flow programming
To solve this problem, this chapter demonstrates that there is a need to raise the programming abstraction and remove the burden of mapping parallelism from programmers.
Dataflow programming models such as StreamIt~\cite{theis2002streamit} and Lime~\cite{auerbach2012lime} offer one part of the solution.
Applications are expressed as dataflow graphs and --- ideally --- the compiler or runtime determines the mapping of parallelism onto the available hardware and controls the grouping of hardware resources.
However, optimally mapping parallelism and managing hardware resources remains an open problem given the sheer complexity of the resulting design space.

% What we do: 1st an analysis
In this chapter, an analysis of the design space is performed and shows the impact of modifying resources and thread mapping.
This analysis is conducted using a set of StreamIt programs that are ran on a verified cycle-level simulator for a tiled reconfigurable architecture with support for core composition.
A machine learning model is developed using the information gathered from the exploration.
This model predicts the best number of threads for a given application and an optimal number of cores to allocate to each thread.

To demonstrate the viability of the approach the results of the predictive model are compared to the best sampled thread and core composition pairing in a space of more than 32,000 design points.
The model matches, and even outperforms in some cases, the performance of the best sampled points in the space, with speedups of up to 9x on a 16 core processor compared to single threaded execution on a single core. 

% contributions
The main contributions of this chapter are:
\vspace{-1mm}
\begin{itemize}
\item An analysis of the co-design space of thread partitioning and core composition;
\item A study on the impact of a simple loop transformation on the optimal core composition;
\item A machine-learning model to determine the optimal core composition and thread partitioning;
\item An analysis of the most important static code features used by the model.
\end{itemize}


The rest of the chapter is structured as follow.
Section~\ref{sec:motiviation} motivates this work by showing the complexity of the design space.
Section~\ref{sec:setup} describes the methodology and section~\ref{sec:streamit:dse} presents an in-depth analysis of the design space.
Section~\ref{sec:ml} develops a machine-learning model to predict the best thread mapping and core composition while Section~\ref{sec:results} shows the performance achieved by the model.
Section~\ref{sec:conclusion} concludes this chapter.
