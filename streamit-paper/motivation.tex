%\begin{figure}[h]
%    \centering
%    \includegraphics[width=0.7\textwidth]{streamit-paper/graphics/beamformer_motivation.pdf}
%    \caption{Distribution of the runtime for Beamformer resulting from an exhaustively exploration of the hardware/software co-design space.
%     The application has been partitioned into different number of threads and core compositions.}
%     \label{fig:beamformermotiv}
%\end{figure}
\subsection{Finding an optimal configuration}
This section motivates the difficulty of finding a good combination of thread and core partitioning.
First, a simple experiment is conducted where the \bench{FilterBank} StreamIt benchmark is analysed using a 16 core dynamic multicore processor.
%Maybe reform this sentence
\bench{FilterBank} distributes its inputs amongst an array of discrete fourier transform (DFT) filters, the outputs of the DFT filters are down-sampled, up-sampled and then recombined to form a processed signal~\cite{streamitrepo}.
The program's tasks are partitioned into threads and a various number of cores are allocated to each of the threads.
Since one of the threads is the master thread which creates and joins all worker threads, this means that the application can be partitioned in up to 15 threads, and 15 cores can be used for those threads.
As each thread must have at least one core assigned to it, and not all cores have to be grouped together, the total number of configurations are:

\begin{equation}
15 + \sum_{threads=2}^{15} \bigg( \sum_{cores=threads}^{15} \frac{(cores-1)!}{(threads-1)!((cores-1)-(threads-1))!}\bigg)
\label{eq:comb}
\end{equation}

In Equation~\ref{eq:comb}, the constant 15 represents the 15 different number of cores that can be composed for the single threaded version.
There are 32,767 combinations (exhaustive space) of thread mappings and core compositions pairings that can be generated.
In this chapter, a design point represents one of these 32,767 different configurations.
Design points are executed on the dynamic multicore simulator, the exact details about the experimental setup are presented later in section~\ref{chp:stream:sec:setup}.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\textwidth]{streamit-paper/graphics/filterbank_motivation_4.pdf}
    \caption{Distribution of speedups for FilterBank when using different core composition and thread pairings compared to single-core single thread. The dots on the X-axis represent specific configurations.}
     \label{fig:threadcoremotiv}
\end{figure}

Figure~\ref{fig:threadcoremotiv} presents the speedup distribution from a subset of the co-design space of \bench{FilterBank} as a density graph.
The speedup is measured by comparing the performance of the configuration to a single-core single thread.
For this Figure, 1316 different thread/core combinations are explored, the reason this number is chosen will be explained later on in section~\ref{chp:stream:sec:setup}.
First, as can be seen in Figure~\ref{fig:threadcoremotiv}, the majority of the different combinations result in a speedup of 2.7x.
It is important to note that as the speedup gets more important, the number of points grows smaller.
For the best speedups, which are far fewer than the average case (4x smaller density than the average case) performance can be improved by up to almost 6x.
Thus, if a good configuration is found, this can yield an important speedup compared to the average configuration.
However, the number of good configurations is low, this underlines the notion that finding a combination of threads and cores is a non-trivial endeavor, as randomly choosing a configuration will result in a sub-optimal performance.
Indeed, even if the average case is 2.7x faster than a single core, Figure~\ref{fig:threadcoremotiv} shows that there exists a good number of configurations that can lead to less than average speedups.


\subsection{Minimizing the search space}
Whilst there exists a large variety of thread-core combinations, certain design choices can be used to try and minimise the space.
For example, choosing to only do multithreading reduces the search space to 15 possible solutions whilst only combinations that lead to homogeneous core compositions reduces the search space to:

\begin{equation}
\sum_{threads=1}^{15} \lfloor\frac{15}{threads}\rfloor= 45
\end{equation}

where the constant 15 represents the number of cores available.
Using only homogeneous core compositions, which facilitates the core partitioning decision, would therefore lead to 45 possible solutions.
However, reducing the search space will limit the potential obtainable speedup.
Figure~\ref{fig:threadcoremotiv} also shows the performance distribution of these design choices.
Their location on the X-axis represents the execution time for that specific configuration.
The points represent a set of different design choices such as only using multithreading, using homogeneous core-compositions with threads and using heterogeneous core-compositions with threads.

As can be seen, using only multithreading can lead to some performance improvements, however it will not result in the optimal performance.
For the \bench{FilterBank} benchmark, 4 threads leads to the fastest execution time when only using multithreading.
This performance is in the highest peak of the density curve, which means that finding the best number of threads for the benchmark will only lead to average performance in this case.
However, using too many threads, for example 15 threads, can lead to a degraded performance compared to the average.
In this case, 15 threads is not much faster than using a single thread.
This is due to the fact that the communication overhead between threads will be too high.

Using the optimal number of threads, which is the number of threads that leads to the fastest execution time without core-composition as a baseline, homogeneous core-composition can then be explored.
In this case only 2 homogeneous pairings exist: 2 cores fused for each of the 4 threads or 3 cores fused for each of the 4 threads.
Figure~\ref{fig:threadcoremotiv} shows that homogeneous core-composition will outperform only using multithreading by 1.3x, however it is not the optimal solution.
In the end, using a heterogeneous configuration leads to a 1.5x speedup compared to the fastest homogeneous configuration.
Therefore, it is important to consider all possible configurations to ensure the possibility of obtaining the best performance.

\subsection{Summary}
Figure~\ref{fig:threadcoremotiv} demonstrates that of the three scenarios that are explored, the heterogeneous core-composition with multiple threads is the optimal solution.
This means that the total space has to be explored in order to ensure that the fastest execution time can be found.
Due to the size of the space and the fact that there can be no apriori about good configurations, using machine learning to predict configurations is a promising approach. % be used to predict good configurations.
By exploring the space with a set of StreamIt benchmarks using different configurations for the processor, a machine learning model can learn what features correlate with the correct configuration.

These two examples illustrates the necessity for designing the technique to predict both the optimal number of threads and core composition to use.
The next section will present a more in-depth analysis of the design space before presenting our machine-learning predictive model.
