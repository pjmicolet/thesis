Chip Multicore Processors (CMP) are now ubiquitous in embedded computing as single threaded performance improvements have slowed.
CMPs have to be carefully designed, balancing the size of each core with the total number of cores on the chip.
Larger cores are typically good at exploiting instruction level parallelism (ILP) but might potentially be very power hungry.
Smaller cores on the other hand require less power but offer limited performance, forcing software developers to parallelize their code with multiple threads, which is a tedious process.
As the size and the number of cores is fixed at design time, choosing the right balance is difficult~\cite{DubachExpl2012, TomuskHet2015}.

Asymmetric Chip Multicore Processors (ACMP) have been proposed~\cite{MittalSurv2016} to overcome this issue.
These processors feature either different sized cores~\cite{JibajaPPerf2016} or different Instruction Set Architectures~\cite{VenkatISADiv2014} to efficiently tackle a multitude of different workloads.
Dynamic Multicore Processors (DMP) push this further by introducing Core Fusion~\cite{ipek2007CoreFusion}.
Similar to ACMPs, Core Fusion allows the chip to have different sized cores, but this can be changed at runtime.
In a DMP, cores can be fused dynamically to create larger cores similar to a superscalar processor.
Any number of cores can potentially be combined together whenever a workload exhibits a large amount of ILP.
When a program exhibits low ILP, the DMP can decouple fused cores to conserve energy.

While a large number of DMPs have been proposed in the literature~\cite{ipek2007CoreFusion,pricopi2012bahurupi,kim2007tflex,Watanabe2010Widget}, these efforts focus on the hardware and microarchitectural design.
They evaluate the hardware using a fixed number of fused cores or provide an oracle for dynamic fusion.
There exists little~\cite{micolet2016dmpstream} to no literature on predicting core fusion from a software perspective.
To the best of our knowledge, there has been no study on dynamically changing the number of cores fused to better match the phases of a workload in a homogeneous DMP compared to ahead of time fusion.

We start with an explanation of the theoretical limitations of core fusion and what we can expect in terms of performance.
We then discuss how classical loop optimizations such as unrolling can have a large impact on performance when fusing cores.
Using the San Diego Vision Benchmark Suite~\cite{sdvbs} (SD-VBS) as a use case, we show that programs exhibit various phases with different amounts of ILP.
We then perform a limit study on the potential for decreasing energy consumption while maintaining performance when adapting the number of cores for each program phase.
Our results show that using dynamic core fusion can save up to 42\% on average while maintaining the same level of performance as a fixed number of cores.
We also show how latency introduced by reconfiguring the system can influence the impact of core fusion.
Finally, we build a simple online model using linear regression that predicts the optimal number of cores per phase for reducing energy consumption while maintaining performance.
This practical model leads to an average of 37\% saving in energy with no performance loss.

To summarize, our contributions are:

\begin{itemize}
\item We analyze the limits of core fusion using an analytical model.
\item We study the loop optimizations required to ensure efficient use of core fusion.
\item We offer an in-depth comparison of static and dynamic core fusion schemes on the San Diego Vision Benchmark Suite.
\item We show that core fusion has the potential to offer a large reduction in energy savings.
\item We show how a simple linear-regression based model can predict the number of cores to fuse for different program phases.
\end{itemize}

