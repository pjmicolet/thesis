This chapter tackled the problem of dynamic reconfiguration of a Dynamic Multicore Processor at runtime.
Due to the fact that adding cores in a core-composition does not result in linear improvements, obtaining the fastest performance comes at the cost of energy.
Therefore using ahead of time static core compositions is not an efficient way of speeding up programs with phases as energy consumption will be high when executing phases with low IPC. % static core compositions are not an efficient method to speed up programs with phases.
Runtime dynamic reconfiguration of DMPs is therefore necessary to ensure that core compositions are used appropriately.

To better understand how core-composition is sensitive to branch prediction and block size, a limit study has been conducted.
It showed that larger core-compositions favour large blocks as this reduces the strain on the branch predictor and also reduces the communication cost between cores.
To improve the size of blocks and block level parallelism, a set of compiler optisations such as loop inversion, loop unrolling and predication have been discussed.

These optimisation were then applied on a set of vision benchmarks, as they are programs that feature varying phases of IPC, and the performance of static core-compositions help show that these programs have phases of IPC patterns.
Using this information, two dynamic runtime reconfiguration schemes are created:  \textbf{DSpeed} that matches the speed of the fastest static core fusion and \textbf{DEff} that maximizes efficiency.
The chapter shows that \textbf{DSpeed} saves on average 42\% energy compared to the optimal static logical core whilst \textbf{DEff} can improve performance by up to 1.30x and reduce energy consumption by 1.20x on some benchmarks.

Finally a linear regression model has been proposed to drive the adaptation process at runtime for \textbf{DSpeed}.
This  model leads to a 37\% reduction in energy whilst maintaining the same level of performance as the optimal static scheme.

Overall, the contributions of this chapter are:

\begin{itemize}
\item An analysis of the limits of core composition via an analytical model that demonstrated that in order for core composition to be effective, blocks must be large to reduce the strain on branch prediction accuracy and the cost of synchronising cores.
%\item A study of the loop optimizations required to ensure efficient use of core fusion such as unrolling and loop interchange which help improve the IPC extracted by core composition by up to 4x. This study underlines the importance of code optimisations to ensure that core compositions can be used to their full effect.
\item An in-depth comparison of static ahead of time and dynamic core composition schemes on the San Diego Vision Benchmark Suite which demonstrated that the benchmarks benefit most from dynamic core composition as it can achieve the same speedups as static ahead of time whilst reducing energy savings.
\item A demonstration that core composition has the potential to offer a large reduction in energy savings of up to 42\% compared to the static ahead of time core composition.
\item An analysis of how the cost of reconfiguring can affect the overall energy savings. The chapter showed that for the set of benchmarks, the reconfiguration cost can be as high as 1000 cycles without greatly impacting performance.
\item A demonstration that a linear-regression based model can predict the number of cores to fuse for different program phases using static code features and can achieve similar energy savings as the optimal execution with 36\% energy savings on average.
\end{itemize} 

%In this paper we have shown that whilst static core fusion already demonstrates promising results, it becomes harder to be efficient when increasing the size of logical cores.
%We explained theoretical limitations of static core fusion; without high branch prediction and large blocks, it under-performs.
%This was followed by a study of a suite of benchmarks, showing how performance varies greatly depending on the size of logical cores. 

%We then created two dynamic schemes: \textbf{DSpeed} that matches the speed of the fastest static core fusion and \textbf{DEff} that maximizes efficiency.
%Using these schemes we saw that \textbf{DSpeed} saves on average 42\% energy compared to the optimal static logical core for a given benchmark.
%We also showed that \textbf{DEff} can improve performance by up to 1.30x and reduce energy consumption by 1.20x on some benchmarks.
%Finally, we developed a simple linear regression model to decide on the number of cores to fuse at runtime to optimize for performance, leading to a 37\% reduction in energy while maintaining the same level of performance as a static scheme.


