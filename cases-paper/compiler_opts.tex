\lstset{
	backgroundcolor=\color{lbcolor},
	tabsize=2,
	rulecolor=,
	language=matlab,
        basicstyle=\tiny,
        upquote=true,
        aboveskip={1\baselineskip},
        columns=fixed,
        showstringspaces=false,
        extendedchars=true,
        breaklines=true,
        prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
        frame=single,
        showtabs=false,
        showspaces=false,
        showstringspaces=false,
        identifierstyle=\ttfamily,
        keywordstyle=\color[rgb]{0,0,1},
        commentstyle=\color[rgb]{0.133,0.545,0.133},
        stringstyle=\color[rgb]{0.627,0.126,0.941},
		numbers=left,
}

\begin{figure}[t]
\lstset{language=C,numbersep=4pt}
\begin{center}
\begin{lstlisting}
for(int i = 0; i < 1000; i++)
  for(int j = 0; j < 1000; j++)
     for(int k = 0;k < 5; k++)
         a[i][j] = a[i][j] * b[k][j];
\end{lstlisting}
\end{center}
\vspace{-2em}
\captionof{lstlisting}{Example of an inner-most loop which should be completely unrolled.}
\label{lst:small}
\vspace{-2em}
\end{figure}

This section describes optimisations focused on reducing control flow and expanding block sizes which is necessary for high performance as seen in section~\ref{sec:lim_study}.

\subsection{Loop Unrolling}
As seen in Chapter~\ref{chp:streamit} Section~\ref{sec:streamit:dse}, loop unrolling can be used to reduce the overhead of the loop header and to better expose Instruction Level Parallelism (ILP).
When dealing with tightly-knit loops, compositions may perform poorly due to the fact that they execute many small blocks, increasing the Synchronization Cost and the branch prediction accuracy requirements.
Unrolling loops reduces the number of blocks required to execute the loop and increases the size of the blocks, thus reducing the Synchronisation Cost and increasing ILP.
For example, the innermost loop in Listing~\ref{lst:small} should be completely unrolled and its outer loop unrolled to increase the block size.

There are certain factors limit the usefulness of loop unrolling.
In the evaluated EDGE architecture, blocks may not have more than 32 load or store instructions as described in Chapter~\ref{chp:Background} section~\ref{sec:edge_isa}.
Therefore unrolling memory intensive loops will not always drastically increase the size of a block if the block is composed mainly of load and store instructions, as the EDGE compiler will have to split blocks if they contain more than 32 load/store instructions.
However as it will generate blocks with fixed branches it reduces the strain on branch prediction.
Another issue is that unrolling loops with conditional statements may not help improve the size of the block as the conditional branches might still segment the new blocks.
So these loops should not be unrolled as they will lead to an increase in code size.


\subsection{Loop Interchange}
When dealing with nested loops there is one reason for interchanging the loops.
The case arises when interchanging the loop removes dependencies in the inner-most loop.
For instance, the dependency in listing~\ref{lst:dep} can be removed by interchanging the loops. 
This allows the compiler to unroll the inner loop efficiently, but also remove any kind of dependency between blocks.
Even if memory dependencies can be detected using a dependence predictor~\cite{chrysos1998storesets}, it can potentially serialise memory operations when multiple iterations of a loop are live.
Thus using loop interchange will reduce any potential data dependency and minimise core communication in a composition.


\begin{figure}[t]
\lstset{language=C,numbersep=4pt}
\begin{center}
\begin{lstlisting}
for(int i = 0; i < 1000; i++)
  for(int j = 0; j < 1000; j++)
      a[i][j] = a[i][j-1] * b[i][j];
\end{lstlisting}
\end{center}
\vspace{-1em}
\captionof{lstlisting}{Data dependency which can be removed via loop interchange.}
\label{lst:dep}
\vspace{1em}
\end{figure}

\subsection{Predication and Hyperblock Formation}
EDGE compilers must split blocks whenever control-flow is present~\cite{smith2006edge} as seen in Section~\ref{chp:bg:sec:edge} of Chapter~\ref{chp:Background}.
If a loop contains a conditional statement, the loop body has to be split in two unless if-conversion is applied.
Hyperblock formation aims to reduce branching and increase block size by combining two or more blocks into a single predicated block~\cite{smith2006edge}.
Hyperblocks reduce both synchronization cost and branch prediction requirements as discussed previously.
This is especially important in control-flow intensive loops where unrolling increases the number of conditional statements.
Hyperblock formation can be done automatically~\cite{smith2006edge} via a compiler flag provided by the EDGE compiler.
However, as of the writing of this thesis, a block can only support a single predication, thus hyperblock formation cannot be paired with loop unrolling for example.

\begin{figure}[t]
     \centering
     \includegraphics[width=\textwidth]{cases-paper/graphics/Exploration/ipc_comp.pdf}
\vspace*{-8mm}
     \caption{Average IPC using the optimal sized logical-core, with and without optimisations. Higher is better.}
     \label{fig:ipccom}
     \vspace{0.5em}
\vspace{5mm}
    \centering
    \includegraphics[width=\textwidth]{cases-paper/graphics/Exploration/comp_speed.pdf}
\vspace*{-8mm}
    \caption{Speedup from using code-optimisations over baseline source code using the same optimal sized logical-core.}
    \label{fig:speedcomp}
\vspace{5mm}
\end{figure}

\subsection{Optimisation Methodology}
While the optimisations described above and their tuning would be easy to implement in a compiler, this thesis did not have access to the compiler's source code.
Therefore the source code of the benchmarks is modified by manually interchanging or unrolling loops.
In the case of predication and hyperblock formation, simple if-then-else statements are converted into ternary operators whenever possible.
Statements are also re-ordered within the body of a loop to avoid having control flow in the middle of the body.
For loop unrolling, the loops were unrolled to fit a single block.
The source code modifications are then verified to have the intended effect by disassembling the binary file produced by the compiler.
On average there are between 0 and 12 loops modifications depending on the benchmark.

\subsection{Results}
First the best static core composition using the optimised code is compared with the unmodified code, both version compiled with \texttt{-O2} which is the highest optimisation setting for the EDGE compiler.
Figure~\ref{fig:ipccom} shows the resulting IPC for the baseline case and the optimised benchmarks when run on a core with the optimal number of composed core to maximise performance.
The IPC of the baseline is very low for the majority of the benchmarks which might give the impression that core composition is rather inefficient.
However, after applying the simple optimisations described above, the average IPC is significantly increased in many cases.

Since optimisations change the total number of instructions, the actual speedup obtained using cycle count is also shown in Figure~\ref{fig:speedcomp}.
As can be seen, benchmarks \bm{MSER} and \bm{Multi-NCut} do not perform any differently.
This is due to the fact that none of these optimisations can be successfully applied on these benchmarks, as the loops cannot be interchanged or unrolled effectively, these applications are discussed in greater detail in Section~\ref{sec:expl}.
For the other benchmarks there is a significant improvements of up to 12$\times$ for \bm{Sift} when the optimisations are applied.
It is important to note that, whilst often the increase in IPC correlates with the speedup, this is not always the case.
In these situations, this is due to the fact that some of the optimisations also reduced the amount of computation required to complete the program; this is the case for \bm{Localization}, \bm{Sift} and \bm{TextureSynthesis}.
These benchmarks benefit from other source code modifications such as forced inlining for \bm{Localization} and \bm{TextureSynthesis} and loop invariant code motion for \bm{Sift} which were also applied manually.

\paragraph*{Summary}

Overall, this section shows that classical loop transformations can have a large impact on the performance of composed cores.
Without these optimisations, it would be more difficult to motivate the use of core fusion even at a static-level as the IPC does not deviate enough from a single core.
