This section now presents the experimental setup used for the remaining parts of the chapter where a thorough evaluation of core composition is conducted with the cycle-level simulator described in Chapter~\ref{chp:setup} Section~\ref{chp:setup:conf}.

\subsection{Benchmarks}

For this chapter the performance of the Dynamic Multi-core Processor (DMP) is studied on a set of Vision Benchmarks designed for hardware and compiler research~\cite{sdvbs} described in Chapter~\ref{chp:setup} Section~\ref{chp:setup:conf}.
The San Diego Vision Benchmark suite (SD-VBS) is composed of nine single-threaded C benchmarks ranging from image analysis to motion tracking.

\begin{table}[t]
  \small
  \centering
 \begin{tabular} {| l | l | l | l | l | l | }
 \hline
   & \cellcolor[gray]{0.7}Disparity & \cellcolor[gray]{0.7} Localization& \cellcolor[gray]{0.7} MSER& \cellcolor[gray]{0.7} Multi\_NCut& \cellcolor[gray]{0.7} Sift\\ \hline
Input&	VGA  & VGA & CIF  & SIM\_FAST& CIF\\ \hline
Cycle Count	&682M  & 526M & 175M  & 180M& 1445M\\ \hline
	
	 & \cellcolor[gray]{0.7} Stitch & \cellcolor[gray]{0.7} SVM & \cellcolor[gray]{0.7} Text. Synth & \cellcolor[gray]{0.7} Tracking&\\ \hline
	  Input & CIF& CIF& FULLHD& VGA &\\ \hline
Cycle count &	  	  571M& 577M& 516M& 374M &\\ \hline

	\end{tabular}
  \caption{Datasets used for each of the benchmarks and the execution time (in cycles) for each of the benchmarks.}\label{tab:sd-data}
  \vspace{2em}
\end{table}


\paragraph*{Input Size}
%Maybe find a way of explaining how long it takes
The SD-VBS benchmark suite comes with a different set of input sizes.
Due to executing these benchmarks on a cycle accurate simulator, executing on large datasets can take a large amount of time.
A single experiment can take up to 6 hours on a single machine (Intel i5 3570k 3GHz, 16 GB of DDR3 RAM), and the average Million instructions per second (MIPS) of the simulator is 0.1 when only simulating a single core.
In the paper describing each of the applications in the SD-VBS suite~\cite{sdvbs}, Venkata {\it et al.~}show that increasing the size of the input does not drastically change the phases of each benchmark.
Table~\ref{tab:sd-data} shows the datasets used for the benchmarks in this chapter.
For this chapter, the aim is to have a dataset that leads to executing at least 100 million cycles as this ensures that the caches and branch predictor are warmed up~\cite{dubach13dynamic}.
The execution time for each of the programs, using a single core, can be found in Table~\ref{tab:sd-data}.
%Multi_NCut would take 10x time longer on anything else

\subsection{Measuring Performance and Power}

The objective of the chapter is to explore how adapting the DMP to the phases of an application can affect performance.
To evaluate dynamic adaptation, it is compared to different static ahead of time configurations.

Five simulations per benchmark are run, one for each core composition size: 1, 2, 4, 8 and 16.
For each the IPC is recorded at an interval of 640 committed blocks.
640 committed blocks is chosen as it allows each core in a core composition to execute enough blocks before taking the measurement.
This is due to the fact that the highest core composition of 16 cores can execute up to 64 blocks at a time, thus recording performance after 640 blocks allows each core to have executed at least 10 blocks.
Using committed blocks allows us to easily compare each simulation as the total number of committed blocks does not change even if the core compositions are different.

The EDGE architecture is fundamentally different from the traditional CISC/RISC paradigm and thus, McPAT~\cite{mcpat} cannot be used to model power consumption as it differs from traditional CISC/RISC cores modelled in McPAT.
Instead a coarse-grained power model is used where power gating is applied; when a core is not currently being used, it is assumed to be turned off and therefore does not consume energy.
Using a coarse grained power model does have some limitations; mainly that when a core is active but not executing code, the model considers that it is still drawing the maximum amount of power possible.
This means that this power model is pessimistic and thus the energy savings shown throughout this chapter may not fully reflect what could be achieved on a real physical processor.
Nonetheless this approach still allows for an analysis of how dynamic adaptation can improve energy consumption.
