\chapter{Setup}\label{chp:setup}

\begin{table}[ht]
\begin{minipage}{0.5\textwidth}
\begin{singlespace}
\begin{tabular} { cc }
      \toprule
      \textbf{Parameter} & \textbf{Values} \\ \midrule
	  Decode \& Dispatch Width & 8  \\
	  Issue Width & 4  \\
	  Number of Lanes & 4 \\
      L1D cache size & 32kB \\
      L1I cache size & 32kB \\
	  
	  \end{tabular}
	  \end{singlespace}
\end{minipage}\hfill
\begin{minipage}{0.5\textwidth}
\begin{singlespace}
\begin{tabular} {cc }
      \toprule
      \textbf{Parameter} & \textbf{Values} \\ \midrule
L2 cache size & 2MB \\
	  \# of MSHR & 8 \\
	  LSQ Organisation & Out of Order \\
	  
	  \end{tabular}
	  \end{singlespace}
\end{minipage}
\caption{Hardware characteristics of a single core of the processor.}\label{tab:processor}
\vspace{-3em}
\end{table}

\section{Dynamic Multicore Processor Simulator}\label{chp:setup:conf}

To evaluate the work a customizable cycle-level simulator for the EDGE architecture is used.
The simulator is verified against RTL implementation of an EDGE core~\cite{putnam2010e2} and is within 5\% from that implementation.
This validation is done by running workloads on RTL and comparing the traces cycle-by-cycle with the software simulator.

To maintain a homogeneous view of the system, the same core configuration was used throughout the thesis.
The features of the core can be found in table~\ref{tab:processor}, and the processor is composed of 16 cores connected via a mesh network, with the L2 Cache being the shared last level cache.
The number of lanes represents how many blocks a single core can hold in its instruction window at a time, and is chosen to be 4 similar to the original work on the E2 EDGE processor~\cite{putnam2010e2}.
Having 16 cores available increases the number of possible configurations of the processor which in turn allows for a more impactfull exploration of core composition.
Whilst previous studies on dynamic multicore processors for EDGE have explored processors with up to 32 cores~\cite{kim2007tflex, gulati2008multitaskingdmc}, in Kim et al.'s work, they determine that 16 cores composed leads to the best average performance.

\section{Benchmarks}
This section covers the different benchmark suites used throughout the thesis.
\begin{table}[t]
\centering
% The FFT need are variable
  \smaller
 \begin{tabular} { | l | l | l | l | l | }
 \hline
  Audiobeam&   Beamformer&  Bitonic-Sort  &  BubbleSort & CFAR \\ \hline
  ChannelVocoder &  FFT& FFT3 & FFT6&  FilterBank \\ \hline
  FIR &  FMRadio &   InsertionSort &   Matmul-Block &  RadixSort\\ \hline
 \end{tabular}
  \caption{StreamIt benchmarks used in this thesis.}\label{tab:streamwl}
\end{table}

\subsection{Streaming applications}\label{chp:setup:streamit}

Chapter~\ref{chp:streamit} demonstrates how configuring a dynamic multicore processor (DMP) to get the optimal performance out of multithreaded applications can be learned.
To explore this concept, choosing a programming language that naturally exposes parallelism is important as it facilitates the process of generating threads for an application.
As the introduction of Chapter~\ref{chp:streamit} will explain, StreamIt is one such language.

The StreamIt repository holds a set of benchmarks that can be used to evaluate the system~\cite{streamitrepo}.
As the processor and tools used throughout this thesis are still in development, some of the applications would either not compile or execute correctly on the provided simulator; thus a subset of the applications are used.
The 15 StreamIt benchmark that worked and are explored in Chapter~\ref{chp:streamit} are shown in Table~\ref{tab:streamwl}.
These applications represent a variety of embedded applications and kernels, from digital signal processing to a matrix-multiplication kernel or band pass filters.
They can be found in a multitude of devices from digital radios to HDTVs and smartphones (audio/video streaming applications).
The benchmarks also present a varying degree of parallelism as will be shown in Chapter~\ref{chp:streamit} Section~\ref{chp:stream:sec:setup}.
As dynamic multicore processors are intended to adapt to the program at hand, having varying amounts of parallelism in the different benchmarks is essential to demonstrate its flexibilitiy.

\subsection{San-Diego Vision Benchmark Suite}\label{chp:setup:sdvbs}
\begin{table}[t]
  \smaller
  \centering
 \begin{tabular} { | l | l | }
 \hline
   \cellcolor[gray]{0.7}Characteristic & \cellcolor[gray]{0.7} Benchmarks\\ \hline
    Memory Intensive & Disparity, Tracking\\ \hline
	Computation Intensive & MSER, SVM, SIFT, Localization,Multi NCut\\\hline
	Memory and Computation Intensive & Stitch\\ \hline
   \end{tabular}
  \caption{Characteristics of the benchmarks~\cite{sdvbs}.}\label{tab:sd-vbschar}
\vspace{1em}
  \end{table}
  
As core composition is designed to improve the performance of single-threaded applications, it is also important to evaluate a set of serial applications.
Chapters~\ref{chp:cases} and \ref{chp:hardchanges} explore a set of Vision Benchmarks designed for hardware and compiler research~\cite{sdvbs}.
The San Diego Vision Benchmark suite (SD-VBS) is composed of nine single-threaded C benchmarks ranging from image analysis to motion tracking.
These benchmarks represent state-of-the-art applications in image and vision recognition which are prevalent in embedded systems.
The domain of image analysis and vision recognition is prevalent in multiple commercial and research fields, such as robotics, self-driving cars and even facial recognition in smartphones.

Vision applications are usually designed as software pipelines featuring different passes which will naturally form phases throughout the execution of the program.
The programs typically have regular and simple control flow which enables the formation of large blocks of instructions.
The processor relies on the ability to form large blocks to exploit block level parallelism (BLP) which makes these applications particularly well suited.
As the results will show, the phase length has minimal impact on energy savings when the reconfiguration overhead is low.

All the benchmarks in the suite are described here:
\begin{itemize}
\item \textbf{Disparity} Computes depth information for a given pair of images.
\vspace{-1em}
\item \textbf{Localization} Estimates position of robot based on its surroundings.
\vspace{-1em}
\item \textbf{MSER} Maximally Stable Extremal Regions, a method used for blob detection in images.
\vspace{-1em}
\item \textbf{Multi NCut} Partitions images into conceptual regions.
\vspace{-1em}
\item \textbf{Sift} Scale invariant feature transform is used to extract and describe items found in an image.
\vspace{-1em}
\item \textbf{Stitch} Combines multiple photographs into a single image.
\vspace{-1em}
\item \textbf{SVM} Support Vector Machine.
\vspace{-1em}
\item \textbf{Texture Synthesis} Creates larger image out of a small sample.
\vspace{-1em}
\item \textbf{Tracking} Extracts motion information from a set of images.
\end{itemize}

and their characteristics in terms of memory/computation intensity are shown in Table~\ref{tab:sd-vbschar}.
\section{Compiler}\label{chp:setup:comp}

All the benchmarks explored in this thesis are compiled using a closed-source EDGE compiler provided by Microsoft.
The benchmarks are compiled with \textit{-O2} optimisations as this is the highest level of optimisations available with hyperblock formation also turned on.
