In EDGE, block dependencies are expressed through register reads and writes.
To ensure that blocks in flight do not execute a register read before an older block has executed a write to the same register, register writes are encoded in the header.
This informs the register-file which can then effectively push back speculative reads from younger blocks.
Whilst this ensures correct execution of speculative blocks, it effectively reduces the potential for block level parallelism (BLP).
This is further exacerbated when composing cores is considered, as this increases the amount of blocks that may potentially have to wait on register reads and writes.
For example, tightly knit loops that write most values out to registers cannot be optimised using core composition due to register dependencies.

In situations where register dependencies are a bottleneck and cannot be optimised via a compiler, core composition cannot be considered an effective method of improving performance.
The problem of trying to reduce register and memory dependencies to improve instruction level parallelism is not new, and is an issue for more traditional superscalar processors.
In these cases value prediction can be used to attempt to ensure that these blocks can run in parallel even if there are dependencies.

\subsection{Implementation}
%Explain TAGE either here or in the background
In this chapter, a Differential Value Tagged Geometric (D-VTAGE) data predictor is implemented.
The D-VTAGE is a computational based data predictor which stores the last value of a register in a Last Value Table (LVT) and also a stride for that value.
When a data prediction is requested, the D-VTAGE predictor simply adds the value from the LVT to the stride.

In the work of Perais et al.~\cite{peraisBeBop2015} they present a D-VTAGE predictor that operates on blocks of instructions rather than single instructions.
This minimizes network pressure on the predictor whilst enabling it to service multiple requests at once.
As EDGE is a block-based ISA by nature, this is a natural fit.
Another consideration is that multiple blocks of the same PC may be speculatively executing at the same time, which could cause data mis-predictions if the predictor is not updated.
This requires current live predictions to be in a speculative window so that new predictions may use the last predicted data and stride.

When a misprediction is detected this is treated in the same way as a load-store dependency miss: the block is only partially flushed by resetting the operands.
This means that blocks do not have to be refetched, simply re-executed with the correct data.

\subsection{Determining block size}

One of the defining factors of the block based D-VTAGE predictor is that a single prediction fetches a fix set of data values rather than requiring one request per instruction.
Due to the fact that the block size is fixed, determining the correct size is important.
Having a large block size means that the D-VTAGE predictor can predict all values in a block, however this comes at the sacrifice of having less blocks in memory.
On the other hand, small block size allows to have multiple blocks stored at a time but means we cannot capture all the data values in an EDGE block.
In this chapter, the data predictor is focused on register reads rather than memory operations.
This is due to the fact that, unless the dependence predictor detects a data dependency between two blocks, memory operations operate in parallel.
Focussing only on register reads will reduce the the block size requirements as reads tend to be a minor component of an EDGE block.

To determine the block size, all the EDGE blocks of the SD-VBS benchmarks are anaylsed to find out the what the average register read count is per block.
To avoid overfitting the data predictor to the set of benchmarks explored in this chapter, different setups of the data predictor are explored to understand how the block size influences performance.
More details are provided in the experimental setup.
