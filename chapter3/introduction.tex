%replace the ref with actual latex ref
The previous chapter showed how reconfiguring a dynamic multicore processor at runtime can improve the efficiency of core composition as it is able to adapt to different phases of instructions per cycle (IPC).
It also demonstrated that there are certain limiting factors to how performant core composition can be.
The limiting factors discussed were branch prediction requirements and cost of synchronizing cores.
To improve the performance of core composition, Chapters~\ref{chp:streamit} and ~\ref{chp:cases} showed that source level modifications are a good method.
These source-level modifications are often used to increase the size of the block which enables better utilisation of large core compositions.

Whilst source-level modifications do in fact improve the performance of large core compositions, they may not always be applicable.
In situations where source or compiler optimisations cannot increase the size of a block, core composition cannot greatly improve the performance of the application.
To increase the viability of core composition, other solutions must therefore be explored.
Instead of solely focusing on improving the source code, analysing how a composition functions at a hardware level can help determine other potential bottlenecks in the system.

When modifications to software cannot yield any performance improvements, it is important to investigate if any hardware modifications can help increase the usefulness of core fusion.
By modifying how core composition behaves, this can potentially improve the performance onflarge compositions.
For example, modifying how blocks are distributed amongst cores can potentially increase the fairness of work distribution, increasing the efficiency of the composition.
This chapter explores the hardware bottlenecks that reduce the efficiency of core composition, and how to address these concerns.

There are two features of the processor that are explored: first how blocks are fetched in a composition, and second how data depenencies between blocks can be handled.
The current fetching model focuses on filling the instruction window of a single core before activating another core in the composition.
Without modifications, this fetching model requires either large blocks to reduce the time required to activate multiple cores in a composition or a fast issue and dispatch width on the core, which increases the complexity of the design.
Thus, exploring how the fetching model can be modified to prioritise using all the cores in the composition over filling a single core can lead to better utilisation of the composition.

Secondly register dependencies can reduce block level paralellism which in turn makes core composition less useful.
Reduced block level parallelism due to data dependencies is similar to an issue found in superscalar processors~\cite{peraisBeBop2015}.
If register values could be predicted, instructions could fire speculatively which in turn would improve block level parallelism.
This chapter therefore explores how a value predictor, which predicts register values to reduce the data dependencies, can be used to improve performance in core composition.

This chapter is organised as follows: first a benchmark previously described in Chapter~\ref{chp:cases} is re-analysed to underline how current hardware does not suffice to ensure performance improvements.
Then a new fetching mechanism called Round Robin Fetch is introduced: cores are able to fetch blocks independently in a round robin fashion to improve fairness.
This is followed by a discussion of how value prediction can be used to resolve data dependencies between blocks and reduce performance penalties caused by the network on chip.
A current state-of-the art predictor is then discussed and shown to be applicable for the EDGE architecture.
Then an exploration of how these hardware modifications affect performance of core composition under an idealistic scenario, where perfect value prediction is enabled is condicted.
The benchmarks used in this chapter are the San-Diego Vision benchmark suite, the same as Chapter~\ref{chp:cases}.
Finally this is then followed by an evaluation of a real value predictor~\cite{peraisBeBop2015}, the block based differential VTAGE predictor (D-VTAGE).
Different parameters of the predictor are modified to understand how value prediction can be adapted to EDGE.

To summarise, the contributions are:

\vspace{-1em}
\begin{itemize}
\item A presentation of a new fetching scheme, Round Robin Fetch.
\vspace{-1em}
\item An analysis of how how value prediction can improve performance of core composition on the SD-VBS benchmark suite~\cite{sdvbs}.
\item An implementation and evaluation of the block-based VTAGE value predictor for EDGE, demonstrating that performance can be improved by only predicting register reads.
\end{itemize}