%replace the ref with actual latex ref
The previous chapter showed how reconfiguring a dynamic multicore processor at runtime can improve the efficiency of core composition as it is able to adapt to different instruction per cycle (IPC) phases.
It also demonstrated that there are certain limiting factors to how performant core composition can be.
The limiting factors discussed were branch prediction requirements and cost of synchronizing cores at commit time.
To improve the performance of core composition, Chapters~\ref{chp:streamit} and ~\ref{chp:cases} showed that source level modifications are a method of improving the performance of core composition performance.
These source-level modifications are often used to increase the size of the block which enables better utility of large core composition sizes.

Whilst source-level modifications do in fact improve the performance of large core compositions, these source level optimisations may not always be applicable.
In situations where source or compiler optimisations cannot increase the size of a block, core composition cannot greatly improve the performance of applications.
To increase the viability of core composition, other solutions must therefore be explored.
Instead of solely focusing on improving the source code, analysing how a core composition functions at a hardware level can help determine other potential bottlenecks in the system.

When modifications to software cannot yield any performance improvements, it is important to investigate if any hardware modifications can help increase the usefulness of core fusion.
By modifying how core composition behaves, this can potentially reduce the software requirements on large compositions.
For example, modifying how blocks are distributed amongst cores can potentially reduce the strain on branch prediction accuracy, making core composition less sensitive to block size at the same time.
This chapter explores the hardware bottlenecks that reduce the efficiency of core composition, and how to address these concerns.

There are two features of the processor that are explored: first how blocks are fetched in a composition, and second how data depenencies between blocks can be handled.
The current fetching model focuses on filling the instruction window of a single core before activating another core in the composition.
Without modifications, this fetching model requires either large blocks to reduce the time required to activate multiple cores in a composition and a fast issue and dispatch width on the core.
Thus, exploring how the fetching model can be modified to prioritise using all the cores in the composition over filling a single core can lead to better utilisation of the composition.

%As for the commit mechanism, it requires that blocks be committed in order, and that cores may not fetch new blocks until one lane of the instruction window has been freed after a commit.
%This means that cores may have blocks in their instruction windows that are only waiting on their turn to commit; for large core compositions with small blocks this can be an issue.
%Adding a way of buffering commits can allow cores to continue fetching blocks as they wait to commit, enabling better utilisation of the composition. 

Finally, register dependencies can reduce block level paralellism which in turn makes core composition less useful.
Reduced block level parallelism due to register dependencies is similar to an issue found in trying to increase instruction level parallelism in superscalar processors~\cite{peraisBeBop2015}.
This chapter explores how a value predictor, which predicts register values to reduce the memory dependencies, can be used to improve performance in core composition.

This chapter is organised as follows: first a benchmark previously described in Chapter~\ref{chp:cases} is re-analysed to underline how current hardware does not suffice to ensure performance improvements.
This is followed by a discussion of how value prediction can be used to resolve data dependencies between blocks, and a current state-of-the art predictor is shown to be applicable for the EDGE architecture.
Then a new fetching mechanism is introduced: one that reduces core communication by allowing cores to fetch independently.
The final section first explores how these hardware modifications affect performance of core composition under an idealistic scenario, where perfect value prediction is enabled.
This is then followed by an evaluation of a real value predictor~\cite{peraisBeBop2015}.
To evaluate how these modifications affect core composition, the San-Diego Vision Benchmark Suite is used once again.

To summarise, the contributions are:

\begin{itemize}
\item A new fetching scheme for core composition.
\item An analysis of how how value prediction can improve performance of core composition on the SD-VBS benchmark suite~\cite{sdvbs}.
\item An implementation of the block-based VTAGE value predictor.
\end{itemize}